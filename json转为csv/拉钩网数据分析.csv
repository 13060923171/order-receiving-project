,公司名称,岗位名称,工资报酬,工作地点,职位福利,岗位职能
0,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
1,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
2,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
3,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
4,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
5,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
6,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
7,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
8,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
9,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
10,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
11,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
12,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
13,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
14,北京升鑫网络科技有限公司,大数据开发工程师,18k-35k,武汉,五险一金、饭补,1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；2、参与图数据库数据流程建设；3、参与图平台开发。
15,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
16,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
17,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
18,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
19,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
20,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
21,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
22,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
23,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
24,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
25,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
26,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
27,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
28,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
29,北京升鑫网络科技有限公司,大数据开发工程师,18k-35k,武汉,五险一金、饭补,1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；2、参与图数据库数据流程建设；3、参与图平台开发。
30,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
31,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
32,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
33,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
34,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
35,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
36,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
37,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
38,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
39,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
40,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
41,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
42,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
43,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
44,北京升鑫网络科技有限公司,大数据开发工程师,18k-35k,武汉,五险一金、饭补,1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；2、参与图数据库数据流程建设；3、参与图平台开发。
45,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
46,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
47,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
48,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
49,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
50,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
51,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
52,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
53,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
54,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
55,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
56,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
57,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
58,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
59,北京升鑫网络科技有限公司,大数据开发工程师,18k-35k,武汉,五险一金、饭补,1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；2、参与图数据库数据流程建设；3、参与图平台开发。
60,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
61,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
62,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
63,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
64,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
65,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
66,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
67,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
68,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
69,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
70,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
71,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
72,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
73,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
74,北京升鑫网络科技有限公司,大数据开发工程师,18k-35k,武汉,五险一金、饭补,1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；2、参与图数据库数据流程建设；3、参与图平台开发。
75,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
76,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
77,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
78,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
79,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
80,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
81,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
82,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
83,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
84,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
85,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
86,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
87,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
88,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
89,北京升鑫网络科技有限公司,大数据开发工程师,18k-35k,武汉,五险一金、饭补,1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；2、参与图数据库数据流程建设；3、参与图平台开发。
90,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
91,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
92,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
93,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
94,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
95,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
96,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
97,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
98,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
99,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
100,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
101,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
102,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
103,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
104,北京升鑫网络科技有限公司,大数据开发工程师,18k-35k,武汉,五险一金、饭补,1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；2、参与图数据库数据流程建设；3、参与图平台开发。
105,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
106,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
107,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
108,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
109,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
110,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
111,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
112,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
113,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
114,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
115,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
116,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
117,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
118,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
119,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
120,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
121,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
122,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
123,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
124,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
125,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
126,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
127,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
128,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
129,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
130,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
131,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
132,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
133,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
134,北京升鑫网络科技有限公司,大数据开发工程师,18k-35k,武汉,五险一金、饭补,1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；2、参与图数据库数据流程建设；3、参与图平台开发。
135,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
136,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
137,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
138,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
139,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
140,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
141,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
142,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
143,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
144,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
145,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
146,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
147,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
148,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
149,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
150,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
151,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
152,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
153,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
154,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
155,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
156,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
157,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
158,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
159,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
160,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
161,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
162,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
163,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
164,北京升鑫网络科技有限公司,大数据开发工程师,18k-35k,武汉,五险一金、饭补,1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；2、参与图数据库数据流程建设；3、参与图平台开发。
165,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
166,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
167,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
168,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
169,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
170,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
171,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
172,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
173,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
174,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
175,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
176,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
177,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
178,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
179,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
180,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
181,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
182,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
183,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
184,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
185,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
186,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
187,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
188,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
189,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
190,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
191,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
192,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
193,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
194,北京升鑫网络科技有限公司,大数据开发工程师,18k-35k,武汉,五险一金、饭补,1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；2、参与图数据库数据流程建设；3、参与图平台开发。
195,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
196,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
197,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
198,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
199,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
200,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
201,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
202,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
203,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
204,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
205,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
206,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
207,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
208,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
209,北京升鑫网络科技有限公司,大数据开发工程师,18k-35k,武汉,五险一金、饭补,1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；2、参与图数据库数据流程建设；3、参与图平台开发。
210,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
211,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
212,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
213,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
214,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
215,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
216,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
217,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
218,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
219,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
220,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
221,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
222,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
223,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
224,北京升鑫网络科技有限公司,大数据开发工程师,18k-35k,武汉,五险一金、饭补,1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；2、参与图数据库数据流程建设；3、参与图平台开发。
225,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
226,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
227,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
228,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
229,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
230,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
231,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
232,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
233,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
234,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
235,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
236,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
237,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
238,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
239,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
240,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
241,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
242,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
243,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
244,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
245,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
246,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
247,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
248,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
249,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
250,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
251,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
252,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
253,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
254,浙江安厨大数据技术有限公司,大数据产品经理,20k-40k,杭州,"蓝海行业,扁平化管理,定期团建",数据中台和驾驶舱、GIS一张图，负责大数据中心业务
255,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
256,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
257,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
258,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
259,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
260,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
261,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
262,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
263,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
264,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
265,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
266,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
267,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
268,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
269,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
270,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
271,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
272,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
273,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
274,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
275,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
276,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
277,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
278,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
279,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
280,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
281,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
282,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
283,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
284,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
285,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
286,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
287,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
288,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
289,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
290,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
291,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
292,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
293,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
294,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
295,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
296,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
297,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
298,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
299,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
300,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
301,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
302,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
303,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
304,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
305,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
306,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
307,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
308,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
309,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
310,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
311,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
312,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
313,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
314,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
315,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
316,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
317,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
318,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
319,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
320,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
321,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
322,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
323,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
324,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
325,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
326,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
327,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
328,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
329,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
330,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
331,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
332,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
333,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
334,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
335,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
336,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
337,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
338,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
339,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
340,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
341,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
342,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
343,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
344,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
345,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
346,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
347,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
348,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
349,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
350,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
351,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
352,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
353,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
354,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
355,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
356,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
357,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
358,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
359,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
360,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
361,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
362,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
363,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
364,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
365,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
366,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
367,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
368,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
369,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
370,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
371,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
372,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
373,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
374,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
375,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
376,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
377,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
378,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
379,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
380,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
381,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
382,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
383,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
384,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
385,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
386,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
387,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
388,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
389,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
390,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
391,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
392,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
393,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
394,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
395,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
396,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
397,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
398,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
399,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
400,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
401,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
402,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
403,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
404,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
405,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
406,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
407,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
408,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
409,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
410,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
411,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
412,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
413,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
414,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
415,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
416,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
417,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
418,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
419,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
420,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
421,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
422,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
423,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
424,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
425,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
426,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
427,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
428,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
429,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
430,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
431,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
432,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
433,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
434,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
435,浙江施强集团有限公司,大数据开发工程师,15k-25k,杭州,五险一金 双休,1.负责在线教育产品的大数据平台和数据仓库的搭建工作； 2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； 4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： 1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； 2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； 3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； 4.熟悉MySQL、MongoDB，具有实际开发经验； 5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； 6.具备团队意识，与他人合作良好，最好具有团队协作的经验。
436,建顺信息科技（广州）有限公司,大数据开发工程师,20k-25k,广州,弹性工作 五险一金 年终奖金,1. 负责产品的数据处理、抽取、清洗、转换工作；2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。任职资格：1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；5. 海量数据处理和挖掘经验者优先；6. 有docker容器服务技术经验优先；7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；建顺总部位于香港，现广州、新加坡、泰、越南、R砦均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。
437,深圳市智灵时代科技有限公司,大数据开发工程师,10k-15k,广州,双休、大牛团队、实力雄厚、AI金融,1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；4、负责利用大数据给客户刻画用户画像及BI报表相关需求；任职要求：1、本科及以上学历，计算机、统计、数学等相关专业毕业；2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；5、能独立完成CDH集群搭建、管理及优化者优先；6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。符合以下条件者优先：1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；2、对开源分布式系统cloudera源码有研究；3、有处理海量数据的经验；4、有金融项目数据分析和挖掘经验优先。团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~
438,深圳三代人科技有限公司,大数据开发工程师,15k-25k,深圳,技术团队氛围好，千万级用户产品团队,"公司自研大数据产品，团队自驱力强，成长空间大。岗位职责1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；4、负责编写相关的技术文档、单元测试，对产品质量负责; 岗位要求 1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"
439,卫盈联信息技术（深圳）有限公司,大数据开发工程师,12k-24k,深圳,核心团队，氛围融洽,1、数据集市、数据仓库架构设计与开发；2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；4、ETL设计与开发。任职资格:1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；3、熟练掌握Airflow调度工具使用；4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；5、熟悉Shell，Python者优先；6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。
440,绿漫科技有限公司,数据开发工程师,15k-25k,杭州,发展空间大 福利待遇好 领导nice,"1.参与大数据平台的设计和开发工作；2.负责基于Hadoop/Spark生态系统的研发；3.负责推荐算法的实现；4.研究大数据技术领域最新进展；任职要求1.本科及以上学历，2年以上的大数据开发经验；2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;4.精通大数据采集、处理、存储、查询相关技术;5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"
441,广州希音供应链管理有限公司,测试工程师,15k-25k,南京,发展前景广阔 大牛云集,1、负责公司商城大数据后端核心接口以及相关系统的测试工作；2、参与需求评审，挖掘需求逻辑漏洞；3、制定测试计划和测试方案；4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；5、控制项目的进度并保证产品的质量；6、编写测试报告，维护测试文档；7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；8、推动测试流程的改进。【岗位要求】1、211本科学历，计算机或通信相关专业；2、对测试行业感兴趣；3、熟悉软件测试理论，熟悉测试流程和测试用例设计；4、了解接口测试相关知识和工具；5、熟悉linux操作系统和数据库；6、至少熟悉一门编程语言；7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；8、具有较强的学习能力和执行力；9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；
442,北京瑞友科技股份有限公司,大数据开发工程师,15k-30k,上海,大型外企 无加班 发展空间大 技术前沿,关键职责包括创建可靠和高性能的大数据和分析解决方案，以支持全球范围内的业务增长。
443,上海引旅信息技术服务有限公司,大数据工程师,20k-30k,上海,大平台，发展空间大，团队nice，办公环境好,1、参与大数据集群维护（包含：离线、实时集群）2、参与大数据平台日常调度管理 和 作业监控3、参与数据平台的设计、数据产品研发 和 数据同步开发4、参与支持业务系统数据服务需求5、参与前沿技术调研和引进，提升工作效率任职要求：1、计算机相关专业，本科及以上学历；2、3年以上工作经验，1年以上大数据平台开发、维护经验；3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理4、熟练使用ETL同步工具（如：kettle、dataX）5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力6、具备shell、python 等脚本编程能力7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，8、能够熟练调用生态圈各组件API接口9、了解实时计算引擎（如：Flink、Spark Streaming）10、有良好的代码编写规范
444,央视市场研究股份有限公司,大数据高级工程师,15k-30k,北京,发展前景远大,1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；2、负责元数据管理、数据治理及数据质量管理的相关工作；3、独立负责数据仓库模块建设，以及数仓上下游对接工作；4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；5、参与项目规划，数据采集设计，数据仓库开发，模型开发；任职资格：1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；8、学习能力强，有团队观念，具备独立解决问题的能力；9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；
445,马来西亚东南亚玩家商城股份有限公司成都代表处,大数据开发工程师,10k-18k,成都,"六险一金,带薪年假,周末双休,节日福利","1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发任职要求：1、计算机相关专业，本科以上学历；3-5年大数据开发经验；2、精通java/python/scala，良好的计算机编程素养；3、熟练Google BigQuery开发；4、熟悉elasticsearch使用，对es集群有一定的维护经验；5、熟悉linux，有丰富的shell脚本经验；6、熟练掌握mysql，有postgresql的使用经验优先；7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。8、有BI 项目开发经验者优先。"
446,广东蓝海启力教育科技有限公司,大数据运维工程师,14k-17k,广州,五险一金,1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。任职要求：1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；10、有大数据开发经验和阅读源码能力者优先。
447,深圳市博悦科创科技有限公司,大数据开发工程师,12k-17k,深圳,五险一金，下午茶，双休,1、熟悉Hadoop、数据仓库理论；2、熟练使用关系数据库，如Oracle，PostgreSQL等; 3、熟练使用Shell、Hql、具备一定的性能调优能力;4、熟练使用至少一种编程语言Java、Python、Scala语言; 5、具备良好的设计和编码规范; 6、具备良好的沟通能力、高度的责任心和团队合作精神; 7、具备良好的抗压、分析和解决问题能力。
448,湖南潭州教育网络科技有限公司,大数据开发工程师,15k-25k,长沙,在线教育领跑者，自研产品，团队300+人,1、负责大数据实时数仓的架构设计、建设与维护2、负责大数据实时应用的研发、维护与优化3、与团队成员配合支持实时处理技术的演进【任职要求】1、本科及以上学历，1年以上实时流开发经验2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\shell等脚本语言5、具有Owner精神，有强自驱力、执行力和跨团队协作能力6、有实际落地的实时数仓、实时平台建设经验优先考虑
449,滴滴优点科技（深圳）有限公司,大数据开发工程师,15k-25k,深圳,扁平化管理 发展空间大,1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； 2. 制定项目设计及实现规范，指导设计、开发及部署工作； 3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。  任职资格： 1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； 2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； 3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。公司介绍：滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。
