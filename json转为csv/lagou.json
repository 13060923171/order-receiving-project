[{"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "18k-35k", "工作地点": "武汉", "公司名称": "北京升鑫网络科技有限公司", "职位福利": "五险一金、饭补", "任职要求": "职责：\n<br>1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；\n<br>2、参与图数据库数据流程建设；\n<br>3、参与图平台开发。\n<br>\n<br>岗位要求：\n<br>1、熟悉常见算法和数据结构；\n<br>2、熟悉Flink原理和源码框架；\n<br>3、熟悉flink离线和实时处理；\n<br>4、熟悉k8s/docker 部署和开发优先；\n<br>5、有安全/推荐应用开发经验优先；\n<br>6、有图数据库neo4j/dgraph/nebula开发和使用经验优先。"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "18k-35k", "工作地点": "武汉", "公司名称": "北京升鑫网络科技有限公司", "职位福利": "五险一金、饭补", "任职要求": "职责：\n<br>1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；\n<br>2、参与图数据库数据流程建设；\n<br>3、参与图平台开发。\n<br>\n<br>岗位要求：\n<br>1、熟悉常见算法和数据结构；\n<br>2、熟悉Flink原理和源码框架；\n<br>3、熟悉flink离线和实时处理；\n<br>4、熟悉k8s/docker 部署和开发优先；\n<br>5、有安全/推荐应用开发经验优先；\n<br>6、有图数据库neo4j/dgraph/nebula开发和使用经验优先。"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "18k-35k", "工作地点": "武汉", "公司名称": "北京升鑫网络科技有限公司", "职位福利": "五险一金、饭补", "任职要求": "职责：\n<br>1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；\n<br>2、参与图数据库数据流程建设；\n<br>3、参与图平台开发。\n<br>\n<br>岗位要求：\n<br>1、熟悉常见算法和数据结构；\n<br>2、熟悉Flink原理和源码框架；\n<br>3、熟悉flink离线和实时处理；\n<br>4、熟悉k8s/docker 部署和开发优先；\n<br>5、有安全/推荐应用开发经验优先；\n<br>6、有图数据库neo4j/dgraph/nebula开发和使用经验优先。"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "18k-35k", "工作地点": "武汉", "公司名称": "北京升鑫网络科技有限公司", "职位福利": "五险一金、饭补", "任职要求": "职责：\n<br>1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；\n<br>2、参与图数据库数据流程建设；\n<br>3、参与图平台开发。\n<br>\n<br>岗位要求：\n<br>1、熟悉常见算法和数据结构；\n<br>2、熟悉Flink原理和源码框架；\n<br>3、熟悉flink离线和实时处理；\n<br>4、熟悉k8s/docker 部署和开发优先；\n<br>5、有安全/推荐应用开发经验优先；\n<br>6、有图数据库neo4j/dgraph/nebula开发和使用经验优先。"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "18k-35k", "工作地点": "武汉", "公司名称": "北京升鑫网络科技有限公司", "职位福利": "五险一金、饭补", "任职要求": "职责：\n<br>1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；\n<br>2、参与图数据库数据流程建设；\n<br>3、参与图平台开发。\n<br>\n<br>岗位要求：\n<br>1、熟悉常见算法和数据结构；\n<br>2、熟悉Flink原理和源码框架；\n<br>3、熟悉flink离线和实时处理；\n<br>4、熟悉k8s/docker 部署和开发优先；\n<br>5、有安全/推荐应用开发经验优先；\n<br>6、有图数据库neo4j/dgraph/nebula开发和使用经验优先。"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "18k-35k", "工作地点": "武汉", "公司名称": "北京升鑫网络科技有限公司", "职位福利": "五险一金、饭补", "任职要求": "职责：\n<br>1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；\n<br>2、参与图数据库数据流程建设；\n<br>3、参与图平台开发。\n<br>\n<br>岗位要求：\n<br>1、熟悉常见算法和数据结构；\n<br>2、熟悉Flink原理和源码框架；\n<br>3、熟悉flink离线和实时处理；\n<br>4、熟悉k8s/docker 部署和开发优先；\n<br>5、有安全/推荐应用开发经验优先；\n<br>6、有图数据库neo4j/dgraph/nebula开发和使用经验优先。"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "18k-35k", "工作地点": "武汉", "公司名称": "北京升鑫网络科技有限公司", "职位福利": "五险一金、饭补", "任职要求": "职责：\n<br>1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；\n<br>2、参与图数据库数据流程建设；\n<br>3、参与图平台开发。\n<br>\n<br>岗位要求：\n<br>1、熟悉常见算法和数据结构；\n<br>2、熟悉Flink原理和源码框架；\n<br>3、熟悉flink离线和实时处理；\n<br>4、熟悉k8s/docker 部署和开发优先；\n<br>5、有安全/推荐应用开发经验优先；\n<br>6、有图数据库neo4j/dgraph/nebula开发和使用经验优先。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "18k-35k", "工作地点": "武汉", "公司名称": "北京升鑫网络科技有限公司", "职位福利": "五险一金、饭补", "任职要求": "职责：\n<br>1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；\n<br>2、参与图数据库数据流程建设；\n<br>3、参与图平台开发。\n<br>\n<br>岗位要求：\n<br>1、熟悉常见算法和数据结构；\n<br>2、熟悉Flink原理和源码框架；\n<br>3、熟悉flink离线和实时处理；\n<br>4、熟悉k8s/docker 部署和开发优先；\n<br>5、有安全/推荐应用开发经验优先；\n<br>6、有图数据库neo4j/dgraph/nebula开发和使用经验优先。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "18k-35k", "工作地点": "武汉", "公司名称": "北京升鑫网络科技有限公司", "职位福利": "五险一金、饭补", "任职要求": "职责：\n<br>1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；\n<br>2、参与图数据库数据流程建设；\n<br>3、参与图平台开发。\n<br>\n<br>岗位要求：\n<br>1、熟悉常见算法和数据结构；\n<br>2、熟悉Flink原理和源码框架；\n<br>3、熟悉flink离线和实时处理；\n<br>4、熟悉k8s/docker 部署和开发优先；\n<br>5、有安全/推荐应用开发经验优先；\n<br>6、有图数据库neo4j/dgraph/nebula开发和使用经验优先。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "18k-35k", "工作地点": "武汉", "公司名称": "北京升鑫网络科技有限公司", "职位福利": "五险一金、饭补", "任职要求": "职责：\n<br>1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；\n<br>2、参与图数据库数据流程建设；\n<br>3、参与图平台开发。\n<br>\n<br>岗位要求：\n<br>1、熟悉常见算法和数据结构；\n<br>2、熟悉Flink原理和源码框架；\n<br>3、熟悉flink离线和实时处理；\n<br>4、熟悉k8s/docker 部署和开发优先；\n<br>5、有安全/推荐应用开发经验优先；\n<br>6、有图数据库neo4j/dgraph/nebula开发和使用经验优先。"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "18k-35k", "工作地点": "武汉", "公司名称": "北京升鑫网络科技有限公司", "职位福利": "五险一金、饭补", "任职要求": "职责：\n<br>1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；\n<br>2、参与图数据库数据流程建设；\n<br>3、参与图平台开发。\n<br>\n<br>岗位要求：\n<br>1、熟悉常见算法和数据结构；\n<br>2、熟悉Flink原理和源码框架；\n<br>3、熟悉flink离线和实时处理；\n<br>4、熟悉k8s/docker 部署和开发优先；\n<br>5、有安全/推荐应用开发经验优先；\n<br>6、有图数据库neo4j/dgraph/nebula开发和使用经验优先。"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "18k-35k", "工作地点": "武汉", "公司名称": "北京升鑫网络科技有限公司", "职位福利": "五险一金、饭补", "任职要求": "职责：\n<br>1、主要负责Flink实时计算平台开发，支撑各个Flink场景应用；\n<br>2、参与图数据库数据流程建设；\n<br>3、参与图平台开发。\n<br>\n<br>岗位要求：\n<br>1、熟悉常见算法和数据结构；\n<br>2、熟悉Flink原理和源码框架；\n<br>3、熟悉flink离线和实时处理；\n<br>4、熟悉k8s/docker 部署和开发优先；\n<br>5、有安全/推荐应用开发经验优先；\n<br>6、有图数据库neo4j/dgraph/nebula开发和使用经验优先。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据产品经理", "薪资": "20k-40k", "工作地点": "杭州", "公司名称": "浙江安厨大数据技术有限公司", "职位福利": "蓝海行业,扁平化管理,定期团建", "任职要求": "备注：数据中台和驾驶舱、GIS一张图，负责大数据中心业务\n<br>\n<br>岗位职责：\n<br>1.负责数据中台、驾驶舱、GIS一张图等其中一款产品0-1的产品规划和设计工作；\n<br>2.通过产品调研、数据分析、竞品跟踪，深入了解用户需求，规划产品。\n<br>3.分析业务方需求，设计原型方案，跟进产品的设计、研发、统筹、上线工作。\n<br>4.以用户体验为中心，结合公司业务模式，设计产品功能，规划、持续迭代优化用户体验。\n<br>5.多个部门沟通协调，快速规划设计产品落地，推动达到产品目标。\n<br>\n<br>岗位要求：\n<br>1、3年及以上数据端产品相关经验，要求沟通能力强，执行力强，责任心突出。\n<br>2、出色的表达能力，文档写作能力，能熟练编写产品方案，逻辑清晰。\n<br>3、丰富的项目管理经验，有较强的用户分层和数据分析，数据挖掘能力。\n<br>4、具备较强的抗压能力，良好的跨团队协作和团队管理能力。\n<br>5、乐观，开朗，热爱生活，善于交流，充满自信。\n<br>6、具有大数据产品设计经验。\n<br>\n<br>安厨的使命是用数据改变农业。\n<br>浙江安厨大数据技术有限公司是一家专注于农业的产业互联网公司，致力于用创新的产品赋能农业部门，帮助其用数字技术变革决策、管理和服务方式，提升其能力和效率，同时为农业主体提供营销平台和服务，帮助其借助新技术的力量直联客户，实现产销高效联动。公司主要经营四项业务：网上农博（浙江省农产品产销对接平台），农业产业服务（县、乡、村农业产业打造），数字乡村建设（市、县、乡农业农村数字化转型），农业产业园（农产品集中配送中心投建）。\n<br>1、网上农博\n<br>网上农博是历史悠久的浙江省农博会在新时代下的改革创新，是服务三农的创新应用，是浙江数字乡村的重要组成部分。平台旨在为乡村产业主体提供免费的营销平台，为消费者提供购买优质农产品和乡村旅游产品的平台，为农业部门提供发展乡村产业的抓手。平台由浙江省农业农村厅主管，安厨提供技术支持和运营管理服务。\n<br>2、产业服务\n<br>产业服务旨在为县、乡、村政府提供完整的乡村产业发展解决方案，通过农产品开发、品牌打造、营销活动、人才培训等一系列专业服务帮其打造乡村特色产业，促进乡村产业发展和助力集体经济增收。\n<br>3、数字乡村\n<br>数字乡村旨在为市、县农业部门提供完整的农业、农村数字化转型解决方案，实现其数字兴业、数字治理、数字服务的目的。数字乡村本质上是农业农村的大数据工程，利用大数据技术提升管理、决策和服务能力，应用于生产管理、流通营销、行业监管、乡村治理、公共服务等农业农村工作领域。\n<br>4、农业产业园\n<br>农业产业园旨在为市、县政府打造一个农业产业的集聚地，产业发展的助推器，农业创客的孵化器，农产品上行的枢纽。园区功能包含集检测、分拣、加工、包装、仓储、冷链、配送等功能的农产品集中配送中心，农业公共服务中心，农产品展销中心，创业办公等功能区块。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "浙江施强集团有限公司", "职位福利": "五险一金 双休", "任职要求": "工作内容： \n<br>1.负责在线教育产品的大数据平台和数据仓库的搭建工作； \n<br>2.负责对海量业务数据以及用户行为数据进行数据分析和数据挖掘的工作； 3.跟进乐课网各系统数据梳理，各数据指标的计算和分析； \n<br>4.参与海量数据的存储、查询和运营数据分析体系搭建，跟踪产品新功能发布以及关键数据上报，为产品迭代提供数据化分析的方法论以及数据支撑。 工作要求： \n<br>1.计算机、通信、数学相关专业毕业，本科专科以上学历，计算机基础扎实，3年及以上工作经验； \n<br>2.精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言； \n<br>3.熟悉Hive、MapReduce等Hadoop生态系统，或Spark生态系统，或Storm或flink，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力，有开源社区代码贡献者优先； \n<br>4.熟悉MySQL、MongoDB，具有实际开发经验； \n<br>5.有较强的业务数据敏感度，较强的数据分析能力，逻辑思考，问题定位解决能力； \n<br>6.具备团队意识，与他人合作良好，最好具有团队协作的经验。"}, {"岗位名称": "大数据开发工程师", "薪资": "20k-25k", "工作地点": "广州", "公司名称": "建顺信息科技（广州）有限公司", "职位福利": "弹性工作 五险一金 年终奖金", "任职要求": "工作职责：\n<br>\n<br>1. 负责产品的数据处理、抽取、清洗、转换工作；\n<br>\n<br>2. 负责各类数据挖掘模型的开发、应用、部署和监控优化。\n<br>\n<br>\n<br>\n<br>任职资格：\n<br>\n<br>1. 计算机相关专业本科以上学历，有3以上年大数据开发经验；\n<br>\n<br>2. 扎实的编程基础，较强的工程实现能力，有Linux下的开发经验，熟悉python/java/scala/，至少能用其中一种coding；\n<br>\n<br>3. 熟悉以下存储：hive/hbase/redis/mongodb/mysql；\n<br>\n<br>4. 熟悉大数据框架技术：kafka/zookeeper/flink，有相关项目实践经验优先；\n<br>\n<br>5. 海量数据处理和挖掘经验者优先；\n<br>\n<br>6. 有docker容器服务技术经验优先；\n<br>\n<br>7. 具有良好的沟通表达能力，有一定的用户需求分析和理解能力；\n<br>\n<br>\n<br>\n<br>\n<br>\n<br>建顺总部位于香港，现广州、新加坡、泰國、越南、馬來西亞均设有分公司，主营业务为为市场提供量身订制的专属配送系统。因公司近年业务急速发展，不断扩张海外市场，现急需IT人才扩大现有团队，组建多条队伍，以分别支持国内与海外线的业务。\n<br>\n<br>\n<br>\n<br>建顺诚邀杰出IT人才加入，我们将向您提供良好的晋升机会、具有竞争力的薪酬福利、五险一金、带薪年假、双休、弹性工作时间，期待您的加入。\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-15k", "工作地点": "广州", "公司名称": "深圳市智灵时代科技有限公司", "职位福利": "双休、大牛团队、实力雄厚、AI金融", "任职要求": "岗位职能：\n<br>1、负责公司数据同步、数据仓库的搭建，熟练使用同步工具如Sqoop，Flume等；\n<br>2、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；\n<br>3、负责Hadoop、HBase、Hive、Spark等集群的维护、 优化工作；\n<br>4、负责利用大数据给客户刻画用户画像及BI报表相关需求；\n<br>\n<br>任职要求：\n<br>1、本科及以上学历，计算机、统计、数学等相关专业毕业；\n<br>2、具有3年或以上互联网基于Hadoop、Hbase等应用开发，具备丰富性能调优经验；\n<br>3、熟悉大数据开发的相关语言，如Java、Python、Scala有大数据开发经验，熟练编写UDF函数；\n<br>4、熟练使用Hive、Hue，有Hive、SQL、ETL开发经验优先；\n<br>5、能独立完成CDH集群搭建、管理及优化者优先；\n<br>6、金融项目或大数据项目开发经验或海量数据处理工作、数据分析和挖掘经验者优先。\n<br>\n<br>符合以下条件者优先：\n<br>1、有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验；\n<br>2、对开源分布式系统cloudera源码有研究；\n<br>3、有处理海量数据的经验；\n<br>4、有金融项目数据分析和挖掘经验优先。\n<br>\n<br>团队成员来自国内外名校，出身阿里、支付宝、华为、中移动、广发银行、唯品会、新浪、万达普惠等知名企业，拥有多年丰富工作经验；股东方资金实力雄厚，无需融资；业内资源丰富，有良好的金融行业合作关系；公司70%以上为技术人员，氛围和谐简单~\n<br>\n<br>或许你没有听到过我们，那是因为我们确实很低调，但低调不代表我们没有实力。作为创业公司的我们，拥有多家股东方的支持，有着丰富的业内资源，还有一群有爱团结的小伙伴，正在茁壮成长的我们，希望优秀的你能够早日加入，和我们一起奋勇前进~"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "深圳三代人科技有限公司", "职位福利": "技术团队氛围好，千万级用户产品团队", "任职要求": "岗位亮点：公司自研大数据产品，团队自驱力强，成长空间大。\n<br>\n<br>岗位职责\n<br>1、负责公司各产品线数据收集、集成、传输、清洗、落地数仓；\n<br>2、负责构建数据开发平台，高效支撑数据任务开发，赋能数据能力，保障数据质量；\n<br>3、负责构建可靠的数据服务，支撑公司各产品数据功能和服务；\n<br>4、负责编写相关的技术文档、单元测试，对产品质量负责; \n<br>岗位要求 \n<br>1、本科及以上学历，计算机相关专业，3年以上实际的大数据业务开发经验，具备 SQL、Python、Scala 语言的开发能力；\n<br>2、深入了解大数据计算平台架构和产品组件原理和应用场景，如 Spark, Hadoop, Hive, HBase,Impala,Flink\n<br>3、熟悉数据仓库理论，数据仓库建模、ETL 设计开发，有数据质量与数据治理相关经验；\n<br>4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力。"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-24k", "工作地点": "深圳", "公司名称": "卫盈联信息技术（深圳）有限公司", "职位福利": "核心团队，氛围融洽", "任职要求": "<p>工作职责:<br/>1、数据集市、数据仓库架构设计与开发；<br/>2、数据研发规范制定、元数据管理，数据治理、数据质量监控，等数据管理工作；<br/>3、建立风控部门的数据主题，开发能够支持风控决策的价值数据和报表；<br/>4、ETL设计与开发。<br/>任职资格:<br/>1、本科及以上学历，计算机、统计学等相关专业、3年及以上大数据数仓工作经验；<br/>2、具有丰富的数据仓库模型设计经验，可独立设计模型，有完整的数仓项目模型设计经验；<br/>3、熟练掌握Airflow调度工具使用；<br/>4、熟悉Hadoop集群、精通SQL语言，精通Hive、Impala、Oracle、MySQL等主流数据库的操作；<br/>5、熟悉Shell，Python者优先；<br/>6、熟悉金融相关业务，有风控业务数据模型设计经验者优先；<br/>7、具有出色的数据敏感度，良好的沟通能力，善于发现问题并能够独立解决问题。</p>"}, {"岗位名称": "数据开发工程师", "薪资": "15k-25k", "工作地点": "杭州", "公司名称": "绿漫科技有限公司", "职位福利": "发展空间大 福利待遇好 领导nice", "任职要求": "岗位职责：\n<br>1.参与大数据平台的设计和开发工作；\n<br>2.负责基于Hadoop/Spark生态系统的研发；\n<br>3.负责推荐算法的实现；\n<br>4.研究大数据技术领域最新进展；\n<br>任职要求\n<br>1.本科及以上学历，2年以上的大数据开发经验；\n<br>2.精通Hadoop,Hbase，Spark,hive,sqoop等大数据技术，熟练掌握一种编程语言，如Scala，Java，R，Python等，熟悉Linux平台；\n<br>3.熟练数据处理流程，数据建模,对数据与业务方面有足够的敏感性;\n<br>4.精通大数据采集、处理、存储、查询相关技术;\n<br>5.有大数据服务运维、性能调优经验，强烈的责任心，对技术充满热情，高效率，良好的沟通能力。"}, {"岗位名称": "测试工程师（南京）-大数据-2022届 (MJ003976)", "薪资": "15k-25k", "工作地点": "南京", "公司名称": "广州希音供应链管理有限公司", "职位福利": "发展前景广阔 大牛云集", "任职要求": "【岗位职责】\n<br>1、负责公司商城大数据后端核心接口以及相关系统的测试工作；\n<br>2、参与需求评审，挖掘需求逻辑漏洞；\n<br>3、制定测试计划和测试方案；\n<br>4、编写测试用例并执行，提交bug，配合开发定位bug，并追踪bug，直至解决bug；\n<br>5、控制项目的进度并保证产品的质量；\n<br>6、编写测试报告，维护测试文档；\n<br>7、配合测试开发维护接口自动化测试用例，提高接口自动化覆盖率；\n<br>8、推动测试流程的改进。\n<br>【岗位要求】\n<br>1、211本科学历，计算机或通信相关专业；\n<br>2、对测试行业感兴趣；\n<br>3、熟悉软件测试理论，熟悉测试流程和测试用例设计；\n<br>4、了解接口测试相关知识和工具；\n<br>5、熟悉linux操作系统和数据库；\n<br>6、至少熟悉一门编程语言；\n<br>7、具有怀疑精神，善于发现和总结问题，并具有跟进问题，并推动解决问题的能力；\n<br>8、具有较强的学习能力和执行力；\n<br>9、具有良好的逻辑思维能力和沟通能力，有责任心，有团队精神；"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-30k", "工作地点": "上海", "公司名称": "北京瑞友科技股份有限公司", "职位福利": "大型外企 无加班 发展空间大 技术前沿", "任职要求": "<p>职位描述：<br/>岗位说明：<br/>关键职责包括创建可靠和高性能的大数据和分析解决方案，以<br/>支持全球范围内的业务增长。<br/><br/>工作职责：<br/>设计和开发大数据解决方案，以帮助产品和业务团队做出数据驱<br/>动的决策。<br/>支持设计、开发和实现数据集成过程的端到端努力。<br/>实现复杂的大数据项目，重点是收集、分析、管理、分析和可视<br/>化大量数据，从而使用多个平台将信息转化为洞察力。<br/>使用Hive、Spark/Spark SQL、Java、 Python和Shell在Hadoop系<br/>统和云平台上构建数据处理应用程序。<br/><br/>岗位要求:<br/>2年以上数据I程或同等经验<br/>具有强大的软件开发背景,必须精通Shell、SQL、 Python、<br/>Java、Scala三种以 上不同的编程语言<br/>对数据仓库概念(如数据模型、ETL概念等)有很好的理解<br/>设计高效、可靠的数据处理管道的经验<br/>掌握Spark&amp;Hadoop生态系统ETL开发(如HDFS、 Hive、 Spark<br/>SQL)<br/>Linux管理、操作及故障排除的理解<br/>深入了解Hadoop/Spark性能调优和底层机制<br/>ETL编排工具(例如气流、Azkaban等) 的工作知识<br/>书面英语能力<br/>良好的文档和沟通技巧，解决用户查询<br/>团队合作和获胜经验丰富<br/>云平台(AWS、GCP、雪花)工作经验优先<br/>数据仓库迁移项目的经验将是一个很好的优势<br/><br/>我们提供的：<br/>与全球团队的挑战性协作<br/>丰富的培训机会<br/>国际职业和竞争性增长机会<br/>与尖端技术和资产合作<br/>免费早餐(星期五)和许多零食、水果、饮料和咖啡<br/>快乐时光与团队建设活动<br/>生日和传统节日礼物</p>"}, {"岗位名称": "大数据工程师", "薪资": "20k-30k", "工作地点": "上海", "公司名称": "上海引旅信息技术服务有限公司", "职位福利": "大平台，发展空间大，团队nice，办公环境好", "任职要求": "岗位职责：\n<br>1、参与大数据集群维护（包含：离线、实时集群）\n<br>2、参与大数据平台日常调度管理 和 作业监控\n<br>3、参与数据平台的设计、数据产品研发 和 数据同步开发\n<br>4、参与支持业务系统数据服务需求\n<br>5、参与前沿技术调研和引进，提升工作效率\n<br>\n<br>任职要求：\n<br>1、计算机相关专业，本科及以上学历；\n<br>2、3年以上工作经验，1年以上大数据平台开发、维护经验；\n<br>3、熟悉Hadoop生态圈 (如：hive、impala、hbase、sqoop、spark、kudu、kylin等等) ，知晓各个组件运行原理\n<br>4、熟练使用ETL同步工具（如：kettle、dataX）\n<br>5、熟悉各类关系型数据库（如：mysql、postgresql、oracle），有良好的sql优化能力，sql编写能力\n<br>6、具备shell、python 等脚本编程能力\n<br>7、有良好的JAVA语言编程基础，通过语言进行至少一个应用类项目开发，\n<br>8、能够熟练调用生态圈各组件API接口\n<br>9、了解实时计算引擎（如：Flink、Spark Streaming）\n<br>10、有良好的代码编写规范\n<br>"}, {"岗位名称": "大数据高级工程师", "薪资": "15k-30k", "工作地点": "北京", "公司名称": "央视市场研究股份有限公司", "职位福利": "发展前景远大", "任职要求": "工作职责：\n<br>1、负责制定数据仓库平台技术体系架构、数据架构及标准规范；\n<br>2、负责元数据管理、数据治理及数据质量管理的相关工作；\n<br>3、独立负责数据仓库模块建设，以及数仓上下游对接工作；\n<br>4、参与数据仓库ETL流程设计、开发和优化，解决ETL过程相关技术问题；\n<br>5、参与项目规划，数据采集设计，数据仓库开发，模型开发；\n<br>任职资格：\n<br>1、5年及以上的数据仓库/BI相关研发经验，对数据和业务敏感，有较好的数据模型设计能力；\n<br>2、参与过大型数据仓库架构设计、模型设计和ETL设计，具备海量数据处理、性能调优的经验；\n<br>3、熟悉数据仓库各类模型建模理论，了解数据仓库数据分层架构，多维数据模型设计；\n<br>4、熟练掌握并使用Hadoop/Spark/Hive/HBase/Impala/Mysql等相关的大数据平台组件、数据库组件；\n<br>5、熟悉Kylin/Druid/Clickhouse等OLAP工具，熟悉业内主流BI产品；\n<br>6、熟悉Cloudera CDH或者阿里云计算EMR等相关产品优先；\n<br>7、有较强的编程能力和编程经验，至少熟悉Java/Scala/Python等其中一门编程语言；\n<br>8、学习能力强，有团队观念，具备独立解决问题的能力；\n<br>9、良好的沟通表达能力，善于总结归纳，用系统化思维解决问题；\n<br>"}, {"岗位名称": "大数据开发工程师", "薪资": "10k-18k", "工作地点": "成都", "公司名称": "马来西亚东南亚玩家商城股份有限公司成都代表处", "职位福利": "六险一金,带薪年假,周末双休,节日福利", "任职要求": "岗位职责：\n<br>\n<br>1、负责大数据相关技术研究，为公司业务的安全、运营、推广提供数据和报表支持；\n<br>2、负责对Google Analytics、Google Tag Manager、FireBase 数据进行采集和存储\n<br>3、负责对公司B2C、C2C电商平台数据库进行同步存储到Google BigQuery\n<br>4、基于Google BigQuery开发公司数据仓库和大数据平台，根据需求实现监控、分析、报表相关功能研发\n<br>\n<br>\n<br>\n<br>任职要求：\n<br>\n<br>1、计算机相关专业，本科以上学历；3-5年大数据开发经验；\n<br>2、精通java/python/scala，良好的计算机编程素养；\n<br>3、熟练Google BigQuery开发；\n<br>4、熟悉elasticsearch使用，对es集群有一定的维护经验；\n<br>5、熟悉linux，有丰富的shell脚本经验；\n<br>6、熟练掌握mysql，有postgresql的使用经验优先；\n<br>7、思路敏捷清晰,良好的表达能力和理解能力，并有一定学习和创新能力。\n<br>8、有BI 项目开发经验者优先。\n<br>"}, {"岗位名称": "大数据运维工程师", "薪资": "14k-17k", "工作地点": "广州", "公司名称": "广东蓝海启力教育科技有限公司", "职位福利": "五险一金", "任职要求": "<p># 大数据运维工程师<br/><br/>岗位职责：<br/><br/>1、负责公司大数据平台的部署、管理、优化、监控报警，保障平台服务7*24稳定可靠高效运行；<br/><br/>2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；<br/><br/>3、开发大数据自动化运维、监控报警、故障处理相关脚本和工具；<br/><br/>4、负责Hadoop/Spark/Flink/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。<br/><br/>任职要求：<br/><br/>1、3年以上互联网运维相关工作经验，2年以上大数据平台运维相关工作经验；<br/><br/>2、具备一定的故障排查能力，有良好的技术敏感度和风险识别能力，精通一门以上脚本语言(shell/python等)，熟悉Http/Https、TCP/IP、SMTP等协议；<br/><br/>3、熟悉Linux(redhat/centos)软硬件环境、系统管理和优化，熟练部署、优化各种常用服务。熟练使用Linux 命令和常用的ssh、ftp、git、maven等开发工具；<br/><br/>4、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDP/HDFS/YARN/Hive/Hbase/Kafka/zookeeper/Spark/Presto/Kylin/Elasticsearch/kibana/MySQL/Oracle等；<br/><br/>5、熟悉Hadoop各组件的原理和实现，有实际部署维护、管理( 包括元数据管理)及优化经验。并拥有持续调优能力，运维管理过大规模数据平台；<br/><br/>6、熟悉掌握常用的安全协议和组件服务，对hadoop各组件的权限、安全、kerberos、ranger进行配置管理。熟悉SSL、ACL、kerberos等在大数据环境场景的使用；<br/><br/>7、熟悉常用运维监控工具（nagios/ganglia/zabbix/grafana/prometheus等）和相关插件的开发。比如邮件、短信、微信报警插件等；<br/><br/>8、熟悉常用nginx／haproxy/varnish/netscaler等代理工具的使用和优化；<br/><br/>9、具备良好的服务意识，善于主动思考，自我驱动力强。有良好的沟通、协调能力，富有团队精神，有较强的文档编写能力；<br/><br/>10、有大数据开发经验和阅读源码能力者优先。</p>"}, {"岗位名称": "大数据开发工程师", "薪资": "12k-17k", "工作地点": "深圳", "公司名称": "深圳市博悦科创科技有限公司", "职位福利": "五险一金，下午茶，双休", "任职要求": "岗位要求：\n<br>1、熟悉Hadoop、数据仓库理论；\n<br>2、熟练使用关系数据库，如Oracle，PostgreSQL等; \n<br>3、熟练使用Shell、Hql、具备一定的性能调优能力;\n<br>4、熟练使用至少一种编程语言Java、Python、Scala语言; \n<br>5、具备良好的设计和编码规范; \n<br>6、具备良好的沟通能力、高度的责任心和团队合作精神; \n<br>7、具备良好的抗压、分析和解决问题能力。"}, {"岗位名称": "大数据开发工程师-实时开发方向", "薪资": "15k-25k", "工作地点": "长沙", "公司名称": "湖南潭州教育网络科技有限公司", "职位福利": "**在线教育领跑者，自研产品，团队300+人", "任职要求": "【岗位职责】\n<br>1、负责大数据实时数仓的架构设计、建设与维护\n<br>2、负责大数据实时应用的研发、维护与优化\n<br>3、与团队成员配合支持实时处理技术的演进\n<br>\n<br>【任职要求】\n<br>1、本科及以上学历，1年以上实时流开发经验\n<br>2、对实时计算体系有自己的见解，深入了解Flink、Spark Streaming等流式处理框架\n<br>3、熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch等的工作原理，有相关平台应用开发经验\n<br>4、至少精通Java、Scala、Python的其中一门语言，熟练掌握sql\\shell等脚本语言\n<br>5、具有Owner精神，有强自驱力、执行力和跨团队协作能力\n<br>6、有实际落地的实时数仓、实时平台建设经验优先考虑"}, {"岗位名称": "大数据开发工程师", "薪资": "15k-25k", "工作地点": "深圳", "公司名称": "滴滴优点科技（深圳）有限公司", "职位福利": "扁平化管理 发展空间大", "任职要求": "岗位职责： \n<br>1. 负责海量数据处理分布式平台以及大数据分析系统架构设计和研发； \n<br>2. 制定项目设计及实现规范，指导设计、开发及部署工作； \n<br>3. 带领、协助指导工程师解决关键问题， 设计开发关键功能模块。 \n<br> \n<br>任职资格： \n<br>1. 计算机相关专业，3年以上互联网核心大数据系统开发经验； \n<br>2. 精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具，具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求； \n<br>3. 掌握高性能、高并发服务设计的基本方法和实现，有大数据分析，算法，可视化方面经验尤佳。\n<br>\n<br>\n<br>\n<br>公司介绍：\n<br>滴滴优点科技（深圳）有限公司于2016年3月由深圳巴士集团、滴滴出行及中科院深圳北斗院三方共同投资成立。滴滴优点基于大数据、物联网和移动互联网技术，专注于智慧公交调度系统和公交共享出行平台研发。“优点出行”、“优点调度”产品已在全国多个城市上线运营。"}]